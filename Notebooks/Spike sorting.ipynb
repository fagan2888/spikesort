{
 "metadata": {
  "name": "Spike sorting"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Spike sorting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab qt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Spike detection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from spikesort.process import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step in spike sorting is to detect and extract spikes from the data.  Typically we work with tetrodes, so the data consists of electrical signals from four electrodes.  We're also going to do this in parallel using multiple IPython engines.\n",
      "\n",
      "First, we need to extract the spike times from all four channels of one tetrode.  Then, we'll use those spike times to build tetrode waveforms which we'll use for clustering spikes.  If we use a common average reference, it is important to detect spike times with the reference, but extract spikes from the data without the reference subtracted.\n",
      "\n",
      "Okay, so start up the engines, I'm going to use four since we have four electrodes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up engines\n",
      "from IPython.parallel import Client\n",
      "c = Client()\n",
      "engines = c[:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set the data file and channels to analyze here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datafile = '/media/hippocampus/NDAQ/datafile_ML_CWM019_120508_001.ns5'\n",
      "chans = tetrode_chans(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = list(load_data(datafile, chans)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered = engines.map(bfilter, data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If using common reference\n",
      "cr_chans = [ i for i in range(16,33) if i not in chans ]\n",
      "cr = common_ref(filtered)\n",
      "#cr_data = [ dat - cr for dat in data ] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if filtered.ready():\n",
      "    print(\"Starting!\")\n",
      "    cr_filtered = [ filt - cr for filt in filtered ]\n",
      "    peaks = engines.map(detect_spikes, cr_filtered)\n",
      "else:\n",
      "    print(\"Not yet...\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If we used a common reference, we need to get the filtered data \n",
      "# without the common reference to extract our final spikes from\n",
      "if peaks.ready():\n",
      "    print(\"Starting!\")\n",
      "    filtered = engines.map(bfilter, data)\n",
      "else:\n",
      "    print(\"Not yet...\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if filtered.ready() & peaks.ready():\n",
      "    print(\"Starting!\")\n",
      "    spikes = form_tetrode(filtered, peaks)\n",
      "else:\n",
      "    print(\"Not yet...\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_spikes('CWM_120508.spks', spikes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that you have detected spikes and saved them, we'll get into grouping the spikes into clusters.  This will helps us identify spikes belonging to different neurons, and to separate out the noise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spikes = load_spikes('/Users/mat/Dropbox/Data/CWM019/CWM019_120508_no_CAR.spks')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(spikes['spikes'][:10].T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}